# 计算机网络

## 第一部分 应用层

应用层协议定义了应用进程间的交互和通信规则，不同主机的应用进程间如何相互传递报文，比如传递的报文的类型、格式、有哪些字段等等。

### HTTP

HTTP 是超文本传输协议，它定义了客户端和服务器之间交换报文的格式和方式，是基于TCP/IP通信协议传递数据，默认使用 80 端口（不涉及数据包（packet）传输）

请求报文：请求行、请求头、空行和请求数据。
响应报文：状态行、消息报头、空行和响应正文。

#### HTTP 方法

- GET：获取资源
  - 该方法是用来请求访问已被 URI 识别的资源
  - 指定的资源经服务器解析后返回相应内容
- POST：传输实体主体
  - 该方法是用来传输实体的主体
  - 与 GET 功能相似，但主要目的并不是获取响应的主体内容
- PUT：传输文件
  - 该方法是用来传输文件的
  - 要求在请求报文的主体中包含文件内容，然后保存到请求 URI 指定的位置
  - 不包含验证机制，所有会存在安全性问题
- HEAD：获得报文首部
  - 与 GET 方法一样，只是不返回报文主体部分
  - 用于确认 URI 的有效性以及资源更新的日期时间等
- DELETE：删除文件
  - 用来删除文件的，刚好与 PUT 方法相反
  - 其是按照请求 URI 删除指定的资源
  - 同样的，该方法也是会存在安全性问题
- OPTIONS：询问支持的方法
  - 用来查询针对请求 URI 指定的资源支持的方法
- TRACE：追踪路径
  - 让 Web 服务器端将之前的请求通信环回给客户端的方法
  - 客户端通过 TRACE 方法查询到发送出去的请求是怎样被加工修改/篡改的
  - 容易引发 XST（Cross-Site Tracing，跨站追踪）攻击
- CONNECT：要求用隧道协议连接代理
  - 要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信
  - 主要使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输

另外还有 PATCH 方法，是对 PUT 方法的补充，用来对已知资源进行局部更新。

#### HTTP 状态码

|  | 类别 | 原因短语 |
|---|---|---|
| 1XX | Informational（信息性状态码） | 接收的请求正在处理 |
| 2XX | Success（成功状态码） | 请求正常处理完毕 |
| 3XX | Redirection（重定向状态码） | 需要进行附加操作以完成请求 |
| 4XX | Client Error（客户端错误状态码） | 服务器无法处理请求 |
| 5XX | Server Error（服务器错误状态码） | 服务器处理请求出错 |

- 200 OK：表示从客户端发来的请求在服务器端被正常处理了
- 204 No Content：代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分
- 206 Partial Content：表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求

- 301 Moved Permanently：永久性重定向。该状态码表示请求的资源已被分配了新的 URI，以后应使用资源现在所指的 URI
- 302 Found：临时性重定向。该状态码表示请求的资源已被分配了新的 URI，希望用户（本次） 能使用新的 URI 访问
- 303 See Other：表示由于请求对应的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源
- 304 Not Modified：表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。本地有缓存的时候，服务器返回的的就是 304
- 307 Temporary Redirect：该状态码与 302 Found 有着相同的含义

- 400 Bad Request：表示请求报文中存在语法错误
- 401 Unauthorized：表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证） 的认证信息
- 403 Forbidden：对请求资源的访问被服务器拒绝了
- 404 Not Found：无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使用。

- 500 Internal Server Error：表明服务器端在执行请求时发生了错误
- 503 Service Unavailable：表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求

#### 存在的问题

1. HTTP 报文使用明文方式发送，可能被第三方窃听。
2. HTTP 报文可能被第三方截取后修改通信内容，接收方没有办法发现报文内容的修改。
3. HTTP 还存在认证的问题，第三方可以冒充他人参与通信。
### HTTP/1.1 协议

HTTP/1.0 协议缺点。每个 TCP 连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 TCP 连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢（slow start）。所以，HTTP 1.0 版本的性能比较差。随着网页加载的外部资源越来越多，这个问题就愈发突出了。为了解决这个问题，有些浏览器在请求时，用了一个非标准的 Connection（keep-alive）字段。

HTTP/1.1 进一步完善了 HTTP 协议，一直用到了 20 年后的今天，直到现在还是最流行的版本。

- 引入持久连接。即 TCP 连接默认不关闭，可以被多个请求复用，不用声明`Connection: keep-alive`
- 引入管道机制。在一个 TCP 连接中，客户端可以同时发送多个请求，进一步改进了 HTTP 协议的效率
- Content-length 字段的作用，声明本次回应的数据长度
- 可以不使用 Content-Length 字段，而使用"分块传输编码"
- 新增了许多动词方法：PUT、PATCH、HEAD、OPTIONS、DELETE
- 客户端请求的头信息新增了 Host 字段，用来指定服务器的域名

虽然 1.1 版允许复用 TCP 连接，但是同一个 TCP 连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为"队头堵塞"（Head-of-line blocking）。

为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接。这导致了很多的网页优化技巧，比如合并脚本和样式表、将图片嵌入 CSS 代码、域名分片（domain sharding）等等。如果 HTTP 协议设计得更好一些，这些额外的工作是可以避免的。

### HTTP/2 协议

HTTP/2 很好的解决了当下最常用的 HTTP/1 所存在的一些性能问题。

1. 二进制协议  
   HTTP/1.1 版的头信息肯定是文本（ASCII 编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"（frame）：头信息帧和数据帧。  
   二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。

2. 多路复用  
   HTTP/2 复用 TCP 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"。  
   这样双向的、实时的通信，就叫做多路复用（Multiplexing）。

3. 数据流  
   因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。  
   HTTP/2 将每个请求或回应的所有数据包，称为一个数据流。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流 ID ，用来区分它属于哪个数据流。  
   客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。

4. 头信息压缩  
   HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如 Cookie 和 User Agent，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。  
   HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用 gzip 或 compress 压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

5. 服务器推送  
   HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。  
   常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析 HTML 源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。

因为 HTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。由于多个数据流使用同一个 TCP 连接，遵守同一个流量状态控制和拥塞控制。只要一个数据流遭遇到拥塞，剩下的数据流就没法发出去，这样就导致了后面的所有数据都会被阻塞。HTTP/2 出现的这个问题是由于其使用 TCP 协议的问题，与它本身的实现其实并没有多大关系。

### HTTP/3 协议

由于 TCP 本身存在的一些限制，Google 就开发了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上。 QUIC 协议在 UDP 协议上实现了多路复用、有序交付、重传等等功能

1. 多路复用  
   虽然 HTTP/2 支持了多路复用，但是 TCP 协议终究是没有这个功能的。QUIC 原生就实现了这个功能，并且传输的单个数据流可以保证有序交付且不会影响其他的数据流，这样的技术就解决了之前 TCP 存在的问题。  
   并且 QUIC 在移动端的表现也会比 TCP 好。因为 TCP 是基于 IP 和端口去识别连接的，这种方式在多变的移动端网络环境下是很脆弱的。但是 QUIC 是通过 ID 的方式去识别一个连接，不管你网络环境如何变化，只要 ID 不变，就能迅速重连上。

2. 0-RTT  
   通过使用类似 TCP 快速打开的技术，缓存当前会话的上下文，在下次恢复会话的时候，只需要将之前的缓存传递给服务端验证通过就可以进行传输了。

3. 纠错机制  
   假如说这次我要发送三个包，那么协议会算出这三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。  
   当出现其中的非校验包丢包的情况时，可以通过另外三个包计算出丢失的数据包的内容。  
   当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包就不能使用纠错机制了，只能使用重传的方式了。

### HTTPS 协议

HTTPS（HTTP Secure）指的是超文本传输安全协议，HTTPS 是基于 HTTP 协议的，不过还会在通信接口部分使用 SSL（Secure Socket Layer）和 TLS（Transport Layer Security）协议代替。因此，有了加密处理、认证和完整性保护功能。但两者是完全不同的连接方式，用的端口也不一样，HTTP 是 80，HTTPS 是 443。

HTTPS 采用共享密钥加密（对称密钥加密）和公开密钥加密（非对称密钥加密）两者并用的混合加密机制。若密钥能够实现安全交换，那么有可能会考虑仅使用公开密钥加密来通信。但是公开密钥加密与共享密钥加密相比，其处理速度要慢。所以应充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。

#### SSL/TLS

通常， HTTP 直接和 TCP 通信。当使用 SSL 时，则演变成先和 SSL 通信，再由 SSL 和 TCP 通信了。在采用 SSL 后， HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能。

SSL/TLS 协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

**握手阶段的详细过程**

1. 客户端先向服务端发出加密通信的请求，这被叫做 ClientHello 请求。请求中包含以下信息：支持的协议版本、 一个客户端生成的随机数、 支持的加密方法、 支持的压缩方法。
2. 服务器收到客户端请求后，向客户端发出回应，这叫 SeverHello。回应中包含以下内容：确认使用的加密通信协议版本、一个服务器生成的随机数、确认使用的加密方法、服务器证书。
3. 客户端收到服务器回应以后，首先验证服务器证书。如果证书没问题，客户端就会从证书中取出服务器的公钥。然后向服务器发送下三项信息：一个随机数、编码改变通知和客户端握手结束通知。
4. 服务器收到客户端的第三个随机数 pre-master key 之后，计算生成本次会话所用的“会话密钥”。然后，向客户端最后发送下面信息：编码改变通知和服务器握手结束通知。

至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用"会话密钥"加密内容。

#### 数字证书

遗憾的是，公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。

为了解决上述问题，可以使用由数字证书认证机构（CA，CertificateAuthority）和其相关机关颁发的公开密钥证书。数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。

此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事，因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。

### WebSocket

HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议；使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输

1. 短轮询

浏览器每隔一段时间向浏览器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应

缺点：浏览器和服务器都很浪费资源，用户增加会导致服务器端压力变大

2. 长轮询

客户端发起请求，服务端判断数据有更新则相应，无响应则挂起。客户端得到响应后才进行下一次请求

缺点：连接挂起后也会导致资源浪费

3. SSE

HTTP/2允许服务器向客户端发送数据流

4. WebSocket

以上三种都是基于HTTP协议的，WebSocket是全双工的协议，可以互相发送消息；

### DNS

主机名到 IP 地址的转换服务，就是我们常说的域名系统；是一个由分层的 DNS 服务器组成的分 布式数据库，是定义了主机如何查询这个分布式数据库的方式的应用层协议。DNS 协议运行在 UDP 协议之上，使用 53 号端口

域名层级：主机名.次级域名.顶级域名.根域名

查询过程
- 请求发送到本地的 DNS 服务器中，本地 DNS 服务 器会判断是否存在该域名的缓存
- 从根域名服务器查到顶级域名服务器的 NS 记录和 A 记录（ IP 地址）
- 从顶级域名服务器查到次级域名服务器的 NS 记录和 A 记录（ IP 地址）
- 从次级域名服务器查出主机名的 IP 地址

DNS 域名解析

在发起 HTTP 请求之前，浏览器首先要做去获得我们想访问网页的 IP 地址，浏览器会发送一个 UDP 的包给 DNS 域名解析服务器。

1. 递归查询
   我们的浏览器、操作系统、路由器都会缓存一些 URL 对应的 IP 地址，统称为 DNS 高速缓存。这是为了加快 DNS 解析速度，使得不必每次都到根域名服务器中去查询。
2. 迭代查询
   迭代查询的方式就是，局部的 DNS 服务器并不会自己向其他服务器进行查询，而是把能够解析该域名的服务器 IP 地址返回给客户端，客户端会不断的向这些服务器进行查询，直到查询到了位置，迭代的话只会帮你找到相关的服务器，然后说我现在比较忙，你自己去找吧。
3. DNS 负载均衡
   DNS 还有负载均衡的作用，现在很多网站都有多个服务器，当一个网站访问量过大的时候，如果所有请求都请求在同一个服务器上，可能服务器就会崩掉，这时候就用到了 DNS 负载均衡技术，当一个网站有多个服务器地址时，在应答 DNS 查询的时候，DNS 服务器会对每个查询返回不同的解析结果，也就是返回不同的 IP 地址，从而把访问引导到不同的服务器上去，来达到负载均衡的目的。例如可以根据每台机器的负载量，或者该机器距离用户的地理位置距离等等条件。

## 第二部分 传输层

传输层协议主要是为不同主机上的不同进程间提供了逻辑通信的功能。传输层只工作在端系统中。

### 传输控制协议 TCP

- 面向连接的，通过三次握手建立连接，在端系统中维护双方连接的状态信息
- 提供可靠的数据传输服务，有序号、确认号、定时重传、校验和等机制
- 对点的服务，在单个发送方和单个接收方之间的连接
- 全双工的服务，连接双方能够向对方发送和接受数据
- 提供了拥塞机制，在网络拥塞的时候会控制发送数据的速率，有助于减少数据包的丢失和减轻网络中的拥塞程度
- 提供了流量控制机制，保证了通信双方的发送和接收速率相同。如果接收方可接收的缓存很小时，发送方会降低发送速率，避免因为缓存填满而造成的数据包的丢失

#### 三次握手

为了准确无误地将数据传送达目标处，TCP 协议采用了三次握手。握手使用了 TCP 的标志（flag）：SYN（synchronize）和 ACK（acknowledgement）

1. 发送端首先发送一个带 SYN 标志的数据包给接收方
2. 接收方收到后，回传一个带 SYN/ACK 标志的数据包以示传达确认消息
3. 发送端再回传一个带 ACK 标志的数据包，代表“握手”结束

如果在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。

**更具体解释**

1. TCP 服务器进程先创建传输控制块 TCB，准备接受客户进程的连接请求，此时服务器进程就处于 LISTEN（监听）状态，等待客户的连接请求。如有，则作出响应；
2. TCP 客户进程也是先创建传输控制块 TCB。然后再打算建立 TCP 连接时，向服务器发出连接请求报文段，这是报文首部中的同部位 `SYN=1`，同时选择一个初始序列号 `seq=x`。TCP 规定，SYN 报文段不能携带数据，但需要消耗掉一个序号。此时，TCP 客户端进程进入了 SYN-SENT（同步已发送）状态。
3. TCP 服务器连接请求报文后，如果同意建立连接，则发出确认报文。确认报文中应该 `ACK=1,SYN=1`，确认号是 `ack=x+1`，同时也要为自己初始化一个序列号 `seq=y`。这个报文段也不能携带数据，但是同样要消耗一个序号。此时，TCP 服务器进程进入了 SYN-RCVD（同步收到）状态。
4. TCP 客户进程收到确认后，还要向服务器给出确认。确认报文的 `ACK=1,ack=y+1`，自己的序列号 `seq=x+1`。TCP 的标准规定，ACK 报文段可以携带数据，但是如果不携带数据则不消耗序号。此时，TCP 连接已经建立，客户端进入 ESTABLISHED（已建立连接）状态。
5. 当服务器收到客户端的确认后也进入 ESTABLISHED 状态，此后双方就可以开始通信了。

![三次握手示意图](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA1MTEwNDA1NjY2?x-oss-process=image/format,png)

在我看来，TCP 三次握手的建立连接的过程就是相互确认初始序号的过程，告诉对方，什么样序号的报文段能够被正确接收。

**第三次握手**

第三次握手的作用是客户端对服务器端的初始序号的确认。如果只使用两次握手，那么服务器就没有办法知道自己的序号是否已被确认。同时这样也是为了防止已失效的请求报文段被服务器接收，而出现错误的情况。

> 所谓“已失效的连接请求报文段”是这样产生的。考虑一种正常情况。A 发出连接请求，但因连接请求报文丢失而未收到确认。于是 A 再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接。A 共发送了两个连接请求报文段，其中第一个丢失，第二个到达了 B。没有“已失效的连接请求报文段”。

> 现假定出现一种异常情况，即 A 发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达 B。本来这是一个早已失效的报文段。但 B 收到此失效的连接请求报文段后，就误认为是 A 又发出一次新的连接请求。于是就向 A 发出确认报文段，同意建立连接。假定不采用三次握手，那么只要 B 发出确认，新的连接就建立了。

> 由于现在 A 并没有发出建立连接的请求，因此不会理睬 B 的确认，也不会向 B 发送数据。但 B 却以为新的运输连接已经建立了，并一直等待 A 发来数据。B 的许多资源就这样白白浪费了。

> 采用三次握手的办法可以防止上述现象的发生。例如在刚才的情况下，A 不会向 B 的确认发出确认。B 由于收不到确认，就知道 A 并没有要求建立连接。

#### 四次挥手

因为 TCP 连接是全双工的，也就是说通信的双方都可以向对方发送和接收消息，所以断开连接需要双方的确认。

1. 客户端向服务器发送一个 FIN 报文段，申请断开连接，发送后客户端进入 FIN_WAIT_1 状态。
2. 服务端接收 FIN 请求后，向客户端发送确认报文段，进入 CLOSE_WAIT 状态，之后不再接收客户端发送过来的数据。客户端收到确认后，进入 FIN_WAIT_2 状态。
3. 服务端发送完所有数据后，向客户端发送 FIN 报文段，申请断开连接，发送后进入 LAST_ACK 状态。
4. 客户端接收 FIN 请求后，向服务器发送一个确认应答，并进入 TIME_WAIT 阶段。该阶段会持续一段时间，如果服务器没有重发请求，那么客户端就进入 CLOSED 的状态。

**更具体的解释**

1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，`FIN=1`，其序列号为`seq=u`，它等于前面已传送过的数据的最后一个字节的序号加 1 ，此时，客户端进入 FIN-WAIT-1 状态。TCP 规定，FIN 报文段即使不携带数据，也要消耗一个序号。
2. 服务器收到连接释放报文，发出确认报文，`ACK=1,ack=u+1`，并且带上自己的序列号 `seq=v`，此时，服务端就进入了 CLOSE-WAIT 状态。TCP 服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个 CLOSE-WAIT 状态持续的时间。
3. 客户端收到服务器的确认请求后，此时，客户端就进入 FIN-WAIT-2 状态，等待服务器发送连接释放报文。
4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，`FIN=1,ack=u+1`，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为 `seq=w`，此时，服务器就进入了 LAST-ACK 状态，等待客户端的确认。
5. 客户端收到服务器的连接释放报文后，必须发出确认，`ACK=1,ack=w+1`，而自己的序列号是 `seq=u+1`，此时，客户端就进入了 TIME-WAIT 状态。注意此时 TCP 连接还没有释放，必须经过 2MSL（最长报文段寿命）的时间后，客户端进入 CLOSED 状态。客户端撤销相应的 TCB 后，就结束了这次的 TCP 连接。
6. 服务器只要收到了客户端发出的确认，立即进入 CLOSED 状态。同样，服务端撤销 TCB 后，就结束了这次的 TCP 连接。可以看到，服务器结束 TCP 连接的时间要比客户端早一些。

[四次挥手示意图](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy?x-oss-process=image/format,png)

**客户端最后等待 2MSL**

最后一次挥手中，客户端会等待一段时间再关闭的原因，是为了防止发送给服务器的确认报文段丢失或者出错，从而导致服务器端不能正常关闭。

为什么 A 在 TIME-WAIT 状态必须等待 2MSL 的时间呢？这有两个理由。

第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 `FIN+ACK` 报文段的确认。B 会超时重传这个 `FIN+ACK` 报文段，而 A 就能在 2MSL 时间内收到这个重传的 `FIN+ACK` 报文段。接着 A 重传一次确认，重新启动 2MSL 计时器。最后，A 和 B 都正常进入到 CLOSED 状态。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 `FIN+ACK` 报文段，因而也不会再发送一次确认报文段。这样，B 就无法按照正常步骤进入 CLOSED 状态。

第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。

### 用户数据协议 UDP

首先 UDP 协议是面向无连接的，也就是说不需要在正式传递数据之前先连接起双方。然后 UDP 协议只是数据报文的搬运工，不保证有序且不丢失的传递到对端，并且 UDP 协议也没有任何控制流量的算法。总的来说 UDP 相较于 TCP 更加的轻便。

1. 面向无连接  
   首先 UDP 是不需要和 TCP 一样在发送数据前进行三次握手建立连接的，想发数据就可以开始发送了。  
   并且也只是数据报文的搬运工，不会对数据报文进行任何拆分和拼接操作。

2. 不可靠性  
   首先不可靠性体现在无连接上，通信都不需要建立连接。  
   并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据也不会关心对方是否已经正确接收到数据了。  
   再者网络环境时好时坏，但是 UDP 因为没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包。

3. 高效  
   头部开销小，只有八字节，相比 TCP 的至少二十字节要少得多，在传输数据报文时是很高效的。

4. 多传输方式  
   不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。
  
适合使用的场景。因为 UDP 高效的特性，在很多实时性要求高的地方都可以看到它的身影。例如直播和实时对战游戏。

## 第三部分 网络安全

### 认证方案
#### 基于 Cookie/Session 的认证方案

由于 HTTP 是一种无状态的协议，服务器单从网络连接上无从知道客户身份。怎么办呢？就给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。因此，cookie 指的就是在浏览器里面存储的一种数据，仅仅是浏览器实现的一种数据存储功能。cookie 的保存时间，可以自己在程序中设置。如果没有设置保存时间，应该是一关闭浏览器，cookie 就自动消失。

Cookie 实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用 response 向客户端浏览器颁发一个 Cookie。客户端浏览器会把 Cookie 保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该 Cookie 一同提交给服务器。服务器检查该 Cookie，以此来辨认用户状态。服务器还可以根据需要修改 Cookie 的内容。

> 注意：Cookie 功能需要浏览器的支持。如果浏览器不支持 Cookie（如大部分手机中的浏览器）或者把 Cookie 禁用了，Cookie 功能就会失效。不同的浏览器采用不同的方式保存 Cookie。IE 浏览器会以文本文件形式保存，一个文本文件保存一个 Cookie。

Cookie 具有不可跨域名性。根据 Cookie 规范，浏览器访问 Google 只会携带 Google 的 Cookie，而不会携带 Baidu 的 Cookie。浏览器判断一个网站是否能操作另一个网站 Cookie 的依据是域名。

**Session**是另一种记录客户状态的机制，不同的是 Cookie 保存在客户端浏览器中，而 Session 保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是 Session。客户端浏览器再次访问时只需要从该 Session 中查找该客户的状态就可以了。

如果说 Cookie 机制是通过检查客户身上的“通行证”来确定客户身份的话，那么 Session 机制就是通过检查服务器上的“客户明细表”来确认客户身份。

session 也是类似的道理，服务器要知道当前发请求给自己的是谁。为了做这种区分，服务器就要给每个客户端分配不同的“身份标识”，然后客户端每次向服务器发请求的时候，都带上这个“身份标识”，服务器就知道这个请求来自于谁了。对于浏览器客户端，大家都默认采用 cookie 的方式，保存这个“身份标识”。

服务器使用 session 把用户的信息临时保存在了服务器上，用户离开网站后 session 会被销毁。这种用户信息存储方式相对 cookie 来说更安。

可是 session 有一个缺陷：如果 web 服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候 session 会丢失。

> 提示：Session 的使用比 Cookie 方便，但是过多的 Session 存储在服务器内存中，会对服务器造成压力。

Cookie 与 Session 的区别和联系

1. cookie 数据存放在客户的浏览器上，session 数据放在服务器上；
2. cookie 不是很安全，别人可以分析存放在本地的 COOKIE 并进行 COOKIE 欺骗，考虑到安全应当使用 session；
3. session 会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能。考虑到减轻服务器性能方面，应当使用 COOKIE；
4. 单个 cookie 在客户端的限制是 3K，就是说一个站点在客户端存放的 COOKIE 不能超过 3K；

Cookie 和 Session 的方案虽然分别属于客户端和服务端，但是服务端的 session 的实现对客户端的 cookie 有依赖关系的，上面我讲到服务端执行 session 机制时候会生成 session 的 id 值，这个 id 值会发送给客户端，客户端每次请求都会把这个 id 值放到 http 请求的头部发送给服务端，而这个 id 值在客户端会保存下来，保存的容器就是 cookie，因此当我们完全禁掉浏览器的 cookie 的时候，服务端的 session 也会不能正常使用。

#### 基于 token 的认证方式

在大多数使用 Web API 的互联网公司中，tokens 是多用户下处理认证的最佳方式。

以下几点特性会让你在程序中使用基于 Token 的身份验证

1. 无状态、可扩展
2. 支持移动设备
3. 跨程序调用
4. 安全

Token 的起源
在介绍基于 Token 的身份验证的原理与优势之前，不妨先看看之前的认证都是怎么做的。

基于服务器的验证
我们都是知道 HTTP 协议是无状态的，这种无状态意味着程序需要验证每一次请求，从而辨别客户端的身份。

在这之前，程序都是通过在服务端存储的登录信息来辨别请求的。这种方式一般都是通过存储 Session 来完成。

基于服务器验证方式暴露的一些问题

1. Seesion：每次认证用户发起请求时，服务器需要去创建一个记录来存储信息。当越来越多的用户发请求时，内存的开销也会不断增加。
2. 可扩展性：在服务端的内存中使用 Seesion 存储登录信息，伴随而来的是可扩展性问题。
3. CORS（跨域资源共享）：当我们需要让数据跨多台移动设备上使用时，跨域资源的共享会是一个让人头疼的问题。在使用 Ajax 抓取另一个域的资源，就可以会出现禁止请求的情况。
4. CSRF（跨站请求伪造）：用户在访问银行网站时，他们很容易受到跨站请求伪造的攻击，并且能够被利用其访问其他的网站。

在这些问题中，可扩展行是最突出的。因此我们有必要去寻求一种更有行之有效的方法。

基于 Token 的验证原理
基于 Token 的身份验证是无状态的，我们不将用户信息存在服务器中。这种概念解决了在服务端存储信息时的许多问题。NoSession 意味着你的程序可以根据需要去增减机器，而不用去担心用户是否登录。

基于 Token 的身份验证的过程如下:

1. 用户通过用户名和密码发送请求。
2. 服务器端程序验证。
3. 服务器端程序返回一个带签名的 token 给客户端。
4. 客户端储存 token,并且每次访问 API 都携带 Token 到服务器端的。
5. 服务端验证 token，校验成功则返回请求数据，校验失败则返回错误码。

图片

Tokens 的优势

1. 无状态、可扩展。在客户端存储的 Tokens 是无状态的，并且能够被扩展。基于这种无状态和不存储 Session 信息，负载负载均衡器能够将用户信息从一个服务传到其他服务器上。tokens 自己 hold 住了用户的验证信息。

2. 安全性。请求中发送 token 而不再是发送 cookie 能够防止 CSRF(跨站请求伪造)。即使在客户端使用 cookie 存储 token，cookie 也仅仅是一个存储机制而不是用于认证。不将信息存储在 Session 中，让我们少了对 session 操作。token 是有时效的，一段时间之后用户需要重新验证。

3. 可扩展性。Tokens 能够创建与其它程序共享权限的程序。

4. 多平台跨域。我们提前先来谈论一下 CORS(跨域资源共享)，对应用程序和服务进行扩展的时候，需要介入各种各种的设备和应用程序。

需要设置有效期吗？
对于这个问题，我们不妨先看两个例子。一个例子是登录密码，一般要求定期改变密码，以防止泄漏，所以密码是有有效期的；另一个例子是安全证书。SSL 安全证书都有有效期，目的是为了解决吊销的问题。所以无论是从安全的角度考虑，还是从吊销的角度考虑，Token 都需要设有效期。

那么有效期多长合适呢？
只能说，根据系统的安全需要，尽可能的短，但也不能短得离谱

然后新问题产生了，如果用户在正常操作的过程中，Token 过期失效了，要求用户重新登录……用户体验岂不是很糟糕？
一种方案，使用 Refresh Token，它可以避免频繁的读写操作。这种方案中，服务端不需要刷新 Token 的过期时间，一旦 Token 过期，就反馈给前端，前端使用 Refresh Token 申请一个全新 Token 继续使用。这种方案中，服务端只需要在客户端请求更新 Token 的时候对 Refresh Token 的有效性进行一次检查，大大减少了更新有效期的操作，也就避免了频繁读写。当然 Refresh Token 也是有有效期的，但是这个有效期就可以长一点了，比如，以天为单位的时间。

时序图表示
使用 Token 和 Refresh Token 的时序图如下：

1. 登录

图片

2. 业务请求

图片

3. Token 过期，刷新 Token

图片

上面的时序图中并未提到 Refresh Token 过期怎么办。不过很显然，Refresh Token 既然已经过期，就该要求用户重新登录了。

项目中使用 token 总结
使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：

1. 前端使用用户名跟密码请求首次登录
2. 后服务端收到请求，去验证用户名与密码是否正确
3. 验证成功后，服务端会根据用户 id、用户名、定义好的秘钥、过期时间生成一个 Token，再把这个 Token 发送给前端
4. 前端收到 返回的 Token ，把它存储起来，比如放在 Cookie 里或者 Local Storage 里

```js
export interface User {
  token: string;
  userInfo: UserInfo | any;
  companyInfo: CompanyInfo | any;
  resources?: string[];
}
save(key: string, value: any, storageType ?: StorageType) {
   return this.storageService.put(
      {
         pool: key,
         key: 'chris-app',
         storageType: StorageType.localStorage
      },
      value
   );
}
this.storageService.save(CACHE_USER_KEY, user);
```

5. 前端每次路由跳转，判断 localStroage 有无 token ，没有则跳转到登录页。有则请求获取用户信息，改变登录状态；6.前端每次向服务端请求资源的时候需要在请求头里携带服务端签发的 Token

```js
(HttpInterceptor) =>
  (headers = headers.set('token', this.authService.getToken()));
```

7. 服务端收到请求，然后去验证前端请求里面带着的 Token。没有或者 token 过期，返回 401。如果验证成功，就向前端返回请求的数据。
8. 前端得到 401 状态码，重定向到登录页面。

```
HttpInterceptor =>
    401: '用户登陆状态失效，请重新登陆。'
```

### 同源策略

在浏览器中，两个不同的源之间若想要相互访问资源或者操作 DOM，那么会有一套基础的安全策略的制约，我们把这称为同源策略。

同源策略主要表现在三个层面。

1. 网络层面  
   限制通过 XMLHttpRequest 等方式将站点的数据发送给不同源的站点
2. DOM 层面  
   限制不同源的 JavaScript 脚本对当前 DOM 对象读写操作
3. 数据层面  
   限制不同源读取当前站点的 Cookie、IndexDB 和 LocalStorage 等数据

### 跨站脚本攻击 XSS

XSS（Cross Site Script）跨站脚本攻击，指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。这些恶意网页程序通常是JavaScript代码，通常攻击方式是对用户浏览器进行控制或者获取用户隐私数据。

1. 可以窃取 Cookie/Web Storage 等敏感信息。在其他电脑上模拟用户的登录，然后进行转账等操作。
2. 可以监听用户行为。获取用户输入的信用卡等信息，将其发送到恶意服务器。
3. 可以通过修改 DOM 伪造假的登录窗口，用来欺骗用户输入用户名和密码等信息。
4. 可以在页面内生成浮窗广告，这些广告会严重地影响用户体验。

注入恶意脚本分 3 种方式：

1. 存储型：即攻击被存储在服务端，常见的是在评论区插入攻击脚本，如果脚本被储存到服务端，那么所有看见对应评论的用户都会受到攻击。
2. 反射型：攻击者将脚本混在 URL 里，服务端接收到 URL 将恶意代码当做参数取出并拼接在 HTML 里返回，浏览器解析此 HTML 后即执行恶意代码。例如 Q 群或者邮件中发送恶意链接，用户点击恶意链接，然后解析 URL 执行恶意代码。
3. DOM 型：攻击者通过各种手段将恶意脚本注入用户的页面中。例如通过网络劫持（WiFi 路由器劫持、本地恶意软件劫持等）在页面传输过程中修改 HTML 页面内容。

防御 XSS 攻击：

- 输入检查：对输入内容中的 `script` 和 `<iframe>` 等标签进行转义或者过滤
- 设置 httpOnly：设置此属性可防止 JavaScript 获取 Cookie，只能在 HTTP 请求过程中使用 Cookie
- 开启 CSP 白名单：即开启白名单，可阻止白名单以外的资源加载和运行
   1. 设置 HTTP 首部中的 Content-Security-Policy
   2. 设置 meta 标签的方式 `<meta http-equiv="Content-Security-Policy">`

### 跨站请求伪造 CSRF

CSRF 攻击（Cross-site request forgery）即跨站请求伪造。是一种劫持受信任用户向服务器发送非预期请求的攻击方式，通常情况下，它是攻击者借助受害者的 Cookie 骗取服务器的信任，但是它并不能拿到 Cookie，也看不到 Cookie 的内容，它能做的就是给服务器发送请求，然后执行请求中所描述的命令，以此来改变服务器中的数据，也就是并不能窃取服务器中的数据。

CSRF 攻击就是黑客利用用户的登录状态，并通过第三方的站点来做一些坏事。

打开攻击者提供的页面后，攻击者有 3 种方式实施 CSRF 攻击：

1. 自动发起 Get 请求。例如请求隐藏在 img 标签内。
2. 自动发起 POST 请求。构建中隐藏表单，自动提交。
3. 引诱用户点击链接。

防御 CSRF 攻击：

- 验证 Token：浏览器请求服务器时，服务器返回一个 token，之后每个请求都需要同时带上 token 和 Cookie 才会被认为是合法请求
- 验证 Referer：通过验证请求头的 Referer 来验证来源站点，但请求头很容易伪造
- 设置 SameSite：设置 Cookie 的 SameSite，可以让 Cookie 不随跨站请求发出，但浏览器兼容不一

### 点击劫持

点击劫持是指在一个 Web 页面中隐藏了一个透明的 iframe，用外层假页面诱导用户点击，实际上是在隐藏的 frame 上触发了点击事件进行一些用户不知情的操作。

X-FRAME-OPTIONS 是一个 HTTP 响应头，在现代浏览器有一个很好的支持。这个 HTTP 响应头 就是为了防御用 iframe 嵌套的点击劫持攻击。

对于某些远古浏览器来说，并不能支持上面的这种方式，那我们只有通过 JS 的方式来防御点击劫持了。代码的作用就是当通过 `iframe` 的方式加载页面时，攻击者的网页直接不显示所有内容了。

### 流量劫持

DNS 劫持。如果当用户通过某一个域名访问一个站点的时候，被篡改的 DNS 服务器返回的是一个恶意的钓鱼站点的 IP，用户就被劫持到了恶意钓鱼站点，然后继而会被钓鱼输入各种账号密码信息，泄漏隐私。

HTTP 劫持主要是当用户访问某个站点的时候会经过运营商网络，而不法运营商和黑产勾结能够截获 HTTP 请求返回内容，并且能够篡改内容，然后再返回给用户，从而实现劫持页面，轻则插入小广告，重则直接篡改成钓鱼网站页面骗用户隐私。能够实施流量劫持的根本原因，是 HTTP 协议没有办法对通信对方的身份进行校验以及对数据完整性进行校验。如果能解决这个问题，则流量劫持将无法轻易发生。所以防止 HTTP 劫持的方法只有将内容加密，让劫持者无法破解篡改，这样就可以防止 HTTP 劫持了。

### 中间人攻击

中间人攻击是攻击方同时与服务端和客户端建立起了连接，并让对方认为连接是安全的，但是实际上整个通信过程都被攻击者控制了。攻击者不仅能获得双方的通信信息，还能修改通信信息。

通常来说不建议使用公共的 Wi-Fi，因为很可能就会发生中间人攻击的情况。如果你在通信的过程中涉及到了某些敏感信息，就完全暴露给攻击方了。

当然防御中间人攻击其实并不难，只需要增加一个安全通道来传输信息。HTTPS 就可以用来防御中间人攻击，但是并不是说使用了 HTTPS 就可以高枕无忧了，因为如果你没有完全关闭 HTTP 访问的话，攻击方可以通过某些方式将 HTTPS 降级为 HTTP 从而实现中间人攻击。


## 其它 常考题目

### 1. Post 和 Get 的区别？

Post 和 Get 是 HTTP 请求的两种方法。

1. 从应用场景上来说，Get 请求是一个幂等的请求，用于对服务器资源不会产生影响的场景，比如说请求一个网页。而 Post 不是一个幂等的请求，一般用于对服务器资源会产生影响的情景。比如注册用户这一类的操作。

2. 因为不同的应用场景，所以浏览器一般会对 Get 请求缓存，但很少对 Post 请求缓存。

3. 在请求参数上，Get 请求中的参数一般不太安全，会拼接到 URL 后面，因此保留在浏览器历史记录中，同时 URL 还有一个长度上的限制。而 POST 的参数支持更多的数据类型，传输数据量一般可以高达 2M。

4. 从发送的报文格式来说，Get 请求的报文中实体部分为空，Post 请求的报文中实体部分 request body 一般为向服务器发送的数据。

### 2. TLS/SSL 中什么一定要用三个随机数，来生成"会话密钥"？

客户端和服务器都需要生成随机数，以此来保证每次生成的秘钥都不相同。使用三个随机数，是因为 SSL 的协议默认不信任每个主机都能产生完全随机的数，如果只使用一个伪随机的数来生成秘钥，就很容易被破解。通过使用三个随机数的方式，增加了自由度，一个伪随机可能被破解，但是三个伪随机就很接近于随机了，因此可以使用这种方法来保持生成秘钥的随机性和安全性。

### 3. SSL 连接断开后如何恢复？

一共有两种方法来恢复断开的 SSL 连接，一种是使用 session ID，一种是 session ticket。

使用 session ID 的方式，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器 如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把。目前所有的浏览器都支持这一种方法。但是 这种方法有一个缺点是，session ID 只能够存在一台服务器上，如果我们的请求通过负载平衡被转移到了其他的服务器上，那 么就无法恢复对话。

另一种方式是 session ticket 的方式，session ticket 是服务器在上一次对话中发送给客户的，这个 ticket 是加密的 ，只有服务器能够解密，里面包含了本次会话的信息，比如对话秘钥和加密方法等。这样不管我们的请求是否转移到其他的服务器 上，当服务器将 ticket 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了。

### 4. RSA 算法的安全性保障？

对极大整数做因数分解的难度决定了 RSA 算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA 算法愈可靠。现在 102 4 位的 RSA 密钥基本安全，2048 位的密钥极其安全。

### 5. DNS 为什么使用 UDP 协议作为传输层协议？

DNS 使用 UDP 协议作为传输层协议的主要原因是为了避免使用 TCP 协议时造成的连接时延。因为为了得到一个域名的 IP 地 址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢，因为大 多数的地址查询请求，都是浏览器请求页面时发出的，这样会造成网页的等待时间过长。

使用 UDP 协议作为 DNS 协议会有一个问题，由于历史原因，物理链路的最小 MTU = 576，所以为了限制报文长度不超过 576， UDP 的报文段的长度被限制在 512 个字节以内，这样一旦 DNS 的查询或者应答报文，超过了 512 字节，那么基于 UDP 的 DNS 协议就会被截断为 512 字节，那么有可能用户得到的 DNS 应答就是不完整的。这里 DNS 报文的长度一旦超过限制，并不 会像 TCP 协议那样被拆分成多个报文段传输，因为 UDP 协议不会维护连接状态，所以我们没有办法确定那几个报文段属于同一 个数据，UDP 只会将多余的数据给截取掉。为了解决这个问题，我们可以使用 TCP 协议去请求报文。

DNS 还存在的一个问题是安全问题，就是我们没有办法确定我们得到的应答，一定是一个安全的应答，因为应答可以被他人伪造， 所以现在有了 DNS over HTTPS 来解决这个问题。

详细资料可以参考：
[《为什么 DNS 使用 UDP 而不是 TCP？》](https://www.zhihu.com/question/310145373)

### 6. 当你在浏览器中输入 Google.com 并且按下回车之后发生了什么？

（1）首先会对 URL 进行解析，分析所需要使用的传输协议和请求的资源的路径。如果输入的 URL 中的协议或者主机名不合法， 将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，如果存在非法字 符，则对非法字符进行转义后再进行下一过程。

（2）浏览器会判断所请求的资源是否在缓存里，如果请求的资源在缓存里并且没有失效，那么就直接使用，否则向服务器发起新 的请求。

（3）下一步我们首先需要获取的是输入的 URL 中的域名的 IP 地址，首先会判断本地是否有该域名的 IP 地址的缓存，如果 有则使用，如果没有则向本地 DNS 服务器发起请求。本地 DNS 服务器也会先检查是否存在缓存，如果没有就会先向根域 名服务器发起请求，获得负责的顶级域名服务器的地址后，再向顶级域名服务器请求，然后获得负责的权威域名服务器的地 址后，再向权威域名服务器发起请求，最终获得域名的 IP 地址后，本地 DNS 服务器再将这个 IP 地址返回给请求的用 户。用户向本地 DNS 服务器发起请求属于递归请求，本地 DNS 服务器向各级域名服务器发起请求属于迭代请求。

（4）当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，因为应用层下发数据给传输层，TCP 协议会指定源 端口号和目的端口号，然后下发给网络层。网络层会将本机地址作为源地址，获取的 IP 地址作为目的地址。然后将下发给 数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，我们本机的 MAC 地址作为源 MAC 地址，目的 MAC 地 址需要分情况处理，通过将 IP 地址与我们本机的子网掩码相与，我们可以判断我们是否与请求主机在同一个子网里，如果 在同一个子网里，我们可以使用 APR 协议获取到目的主机的 MAC 地址，如果我们不在一个子网里，那么我们的请求应该 转发给我们的网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应 该为网关的地址。

（5）下面是 TCP 建立连接的三次握手的过程，首先客户端向服务器发送一个 SYN 连接请求报文段和一个随机序号，服务端接 收到请求后向服务器端发送一个 SYN ACK 报文段，确认连接请求，并且也向客户端发送一个随机序号。客户端接收服务器的 确认应答后，进入连接建立的状态，同时向服务器也发送一个 ACK 确认报文段，服务器端接收到确认后，也进入连接建立 状态，此时双方的连接就建立起来了。

（6）如果使用的是 HTTPS 协议，在通信前还存在 TLS 的一个四次握手的过程。首先由客户端向服务器端发送使用的协议的版 本号、一个随机数和可以使用的加密方法。服务器端收到后，确认加密的方法，也向客户端发送一个随机数和自己的数字证 书。客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机数，并使用证书中的公钥对随机数加密，然后 发送给服务器端，并且还会提供一个前面所有内容的 hash 值供服务器端检验。服务器端接收后，使用自己的私钥对数据解 密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。这个时候双方都有了三个随机数，按照之前所约定的加 密方法，使用这三个随机数生成一把秘钥，以后双方通信前，就使用这个秘钥对数据进行加密后再传输。

（7）当页面请求发送到服务器端后，服务器端会返回一个 html 文件作为响应，浏览器接收到响应后，开始对 html 文件进行 解析，开始页面的渲染过程。

（8）浏览器首先会根据 html 文件构建 DOM 树，根据解析到的 css 文件构建 CSSOM 树，如果遇到 script 标签，则判端 是否含有 defer 或者 async 属性，要不然 script 的加载和执行会造成页面的渲染的阻塞。当 DOM 树和 CSSOM 树建 立好后，根据它们来构建渲染树。渲染树构建好后，会根据渲染树来进行布局。布局完成后，最后使用浏览器的 UI 接口对页 面进行绘制。这个时候整个页面就显示出来了。

（9）最后一步是 TCP 断开连接的四次挥手过程。

详细资料可以参考：
[《当你在浏览器中输入 Google.com 并且按下回车之后发生了什么？》](http://blog.jobbole.com/84870/)

### 7. 谈谈 CDN 服务？

CDN 是一个内容分发网络，通过对源网站资源的缓存，利用本身多台位于不同地域、不同运营商的服务器，向用户提供资就近访问的 功能。也就是说，用户的请求并不是直接发送给源网站，而是发送给 CDN 服务器，由 CND 服务器将请求定位到最近的含有该资源 的服务器上去请求。这样有利于提高网站的访问速度，同时通过这种方式也减轻了源服务器的访问压力。

详细资料可以参考：
[《CDN 是什么？使用 CDN 有什么优势？》](https://www.zhihu.com/question/36514327?rf=37353035)

### 8. 什么是正向代理和反向代理？

我们常说的代理也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的 服务都被代理服务器代替来请求。

反向代理隐藏了真实的服务端，当我们请求一个网站的时候，背后可能有成千上万台服务器为我们服务，但具体是哪一台，我们不知 道，也不需要知道，我们只需要知道反向代理服务器是谁就好了，反向代理服务器会帮我们把请求转发到真实的服务器那里去。反向 代理器一般用来实现负载平衡。

详细资料可以参考：
[《正向代理与反向代理有什么区别》](https://mp.weixin.qq.com/s/ikrI3rmSYs83wdSWqq2QIg?)
[《webpack 配置 proxy 反向代理的原理是什么？》](https://segmentfault.com/q/1010000017502539/a-1020000017532348)

### 9. 负载平衡的两种实现方式？

一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实 现集群的负载平衡。

另一种是 DNS 的方式，DNS 可以用于在冗余的服务器上实现负载平衡。因为现在一般的大型网站使用多台服务器提供服务，因此一 个域名可能会对应多个服务器地址。当用户向网站域名请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合，但在 每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。以此将用户的请求均衡的分配到各个不同的服 务器上，这样来实现负载均衡。这种方式有一个缺点就是，由于 DNS 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解 析仍然返回的是那个 IP 地址，就会造成访问的问题。

详细资料可以参考：
[《负载均衡的原理》](https://mp.weixin.qq.com/s?__biz=MzA5Njc2OTg4NQ==&mid=2247483870&idx=1&sn=bab36544ec62c394c104df699cf85154&chksm=90aa43eca7ddcafa01634cefee12fd8a332250d3f49d8b6647f536c215ac297e4b6a53af8253#rd)

### 10. http 请求方法 options 方法有什么用？

OPTIONS 请求与 HEAD 类似，一般也是用于客户端查看服务器的性能。这个方法会请求服务器返回该资源所支持的所有 HTTP 请 求方法，该方法会用'\*'来代替资源名称，向服务器发送 OPTIONS 请求，可以测试服务器功能是否正常。JS 的 XMLHttpRequest 对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。

相关资料可以参考：
[《HTTP 请求方法》](https://itbilu.com/other/relate/EkwKysXIl.html)

### 11. http1.1 和 http1.0 之间有哪些区别？

http1.1 相对于 http1.0 有这样几个区别：
（1）连接方面的区别，http1.1 默认使用持久连接，而 http1.0 默认使用非持久连接。http1.1 通过使用持久连接来使多个 http 请求复用同一个 TCP 连接，以此来避免使用非持久连接时每次需要建立连接的时延。
（2）资源请求方面的区别，在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，http1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

（3）缓存方面的区别，在 http1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，http1.1 则引入了更多的缓存控制策略例如 Etag、If-Unmodified-Since、If-Match、If-None-Match 等更多可供选择的缓存头来控制缓存策略。

（4）http1.1 中还新增了 host 字段，用来指定服务器的域名。http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个 IP 地址。因此有了 host 字段，就可以将请求发往同一台服务器上的不同网站。

（5）http1.1 相对于 http1.0 还新增了很多方法，如 PUT、HEAD、OPTIONS 等。

详细资料可以参考：
[《HTTP1.0、HTTP1.1 和 HTTP2.0 的区别》](https://juejin.im/entry/5981c5df518825359a2b9476)
[《HTTP 协议入门》](http://www.ruanyifeng.com/blog/2016/08/http.html)
[《网络---一篇文章详解请求头 Host 的概念》](https://blog.csdn.net/netdxy/article/details/51195560)

### 12. 网站域名加 www 与不加 www 的区别？

详细资料可以参考：
[《为什么域名前要加 www 前缀 www 是什么意思？》](https://www.f9seo.com/post-816.html)
[《为什么越来越多的网站域名不加「www」前缀？》](https://www.zhihu.com/question/20414602)
[《域名有 www 与没有 www 有什么区别？》](https://blog.csdn.net/andybruse/article/details/7982278)

### 13. 即时通讯的实现，短轮询、长轮询、SSE 和 WebSocket 间的区别？

短轮询和长轮询的目的都是用于实现客户端和服务器端的一个即时通讯。

短轮询的基本思路就是浏览器每隔一段时间向浏览器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行 响应。这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客 户端能够模拟实时地收到服务器端的数据的变化。这种方式的优点是比较简单，易于理解。缺点是这种方式由于需要不断的建立 ht tp 连接，严重浪费了服务器端和客户端的资源。当用户增加时，服务器端的压力就会变大，这是很不合理的。

长轮询的基本思路是，首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将 这个请求挂起，然后判断服务器端数据是否有更新。如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回。 客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。长轮询和短轮询比起来，它的 优点是明显减少了很多不必要的 http 请求次数，相比之下节约了资源。长轮询的缺点在于，连接挂起也会导致资源的浪费。

SSE 的基本思想是，服务器使用流信息向服务器推送信息。严格地说，http 协议无法做到服务器主动推送信息。但是，有一种变通 方法，就是服务器向客户端声明，接下来要发送的是流信息。也就是说，发送的不是一次性的数据包，而是一个数据流，会连续不断 地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，视频播放就是这样的例子。SSE 就是利用这种机 制，使用流信息向浏览器推送信息。它基于 http 协议，目前除了 IE/Edge，其他浏览器都支持。它相对于前面两种方式来说，不 需要建立过多的 http 请求，相比之下节约了资源。

上面三种方式本质上都是基于 http 协议的，我们还可以使用 WebSocket 协议来实现。WebSocket 是 Html5 定义的一个新协 议，与传统的 http 协议不同，该协议允许由服务器主动的向客户端推送信息。使用 WebSocket 协议的缺点是在服务器端的配置 比较复杂。WebSocket 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息，而 SSE 的方式是单向通信的，只能 由服务器端向客户端推送信息，如果客户端需要发送信息就是属于下一个 http 请求了。

详细资料可以参考：
[《轮询、长轮询、长连接、websocket》](https://cloud.tencent.com/developer/article/1076547)
[《Server-Sent Events 教程》](http://www.ruanyifeng.com/blog/2017/05/server-sent_events.html)
[《WebSocket 教程》](http://www.ruanyifeng.com/blog/2017/05/websocket.html)

### 14. 怎么实现多个网站之间共享登录状态

在多个网站之间共享登录状态指的就是单点登录。多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。

我认为单点登录可以这样来实现，首先将用户信息的验证中心独立出来，作为一个单独的认证中心，该认证中心的作用是判断客户端发 送的账号密码的正确性，然后向客户端返回对应的用户信息，并且返回一个由服务器端秘钥加密的登录信息的 token 给客户端，该 token 具有一定的有效时限。当一个应用系统跳转到另一个应用系统时，通过 url 参数的方式来传递 token，然后转移到的应用站 点发送给认证中心，认证中心对 token 进行解密后验证，如果用户信息没有失效，则向客户端返回对应的用户信息，如果失效了则将 页面重定向会单点登录页面。

详细资料可以参考：
[《HTTP 是个无状态协议，怎么保持登录状态？》](https://www.zhihu.com/question/35906139)

